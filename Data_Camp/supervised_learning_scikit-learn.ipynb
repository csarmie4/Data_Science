{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "Two types of supervised learning — classification and regression \\\n",
    "K-Nearest Neighbors(KNN): classification problem that makes predictions based on what label the majority of nearest neighbors have \\\n",
    "<b>from sklearn.neighbors import KNeighborsClassifier</b> Used for KNN \\\n",
    "<b>X = df[[\"feature_1\", \"feature_2]].values</b> Split data into X, a 2D array of the features. .values attribute converts X and y into NumPy arrays \\\n",
    "<b>y = df[\"target\"].values</b> y, a 1D array of target values \\\n",
    "<b>knn = KNeighborsClassifier(n_neighbors=15)</b> Instantiate the KNN \\ \n",
    "<b>knn.fit(X, y)</b> fit the classifier \\\n",
    "<b>predictions = knn.predict(X_new)</b> Predict new data stored in X_new variable \\\n",
    "<b>print(\"Predictions: {}\".format(predictions))</b> Print out predictions \\\n",
    "<br></br>\n",
    "Measuring model performance/accuracy \\\n",
    "<b>from sklearn.model_selection import train_test_split</b> Used below \\\n",
    "<b>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.3, random_state=21, stratify=y)</b> 30% of the data will be used as testing, random_state sets a seed that splits the data, stratify ensures the split reflects the proportion of labels in our data \\\n",
    "<b>knn.score(X_test, y_test)</b> Check accuracy \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features to use will be \"account_length\" and \"customer_service_calls\". The target, \"churn\", needs to be a single column with the same number of observations as the feature data.\n",
    "<br></br>\n",
    "You will convert the features and the target variable into NumPy arrays, create an instance of a KNN classifier, and then fit it to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "churn_df = pd.read_csv(\"telecom_churn_clean.csv\")\n",
    "\n",
    "# Create arrays for the features and the target variable\n",
    "y = churn_df[\"churn\"].values\n",
    "X = churn_df[[\"account_length\", \"customer_service_calls\"]].values\n",
    "\n",
    "# Create a KNN classifier with 6 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[30.0, 17.5],\n",
    "                  [107.0, 24.1],\n",
    "                  [213.0, 10.9]])\n",
    "\n",
    "# Predict the labels for the X_new\n",
    "y_pred = knn.predict(X_new)\n",
    "\n",
    "# Print the predictions for X_new\n",
    "print(\"Predictions: {}\".format(y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = churn_df.drop(\"churn\", axis=1).values\n",
    "y = churn_df[\"churn\"].values\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neighbors\n",
    "neighbors = np.arange(1, 13)\n",
    "train_accuracies = {}\n",
    "test_accuracies = {}\n",
    "\n",
    "for neighbor in neighbors:\n",
    "  \n",
    "\t# Set up a KNN Classifier\n",
    "\tknn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "  \n",
    "\t# Fit the model\n",
    "\tknn.fit(X_train, y_train)\n",
    "  \n",
    "\t# Compute accuracy\n",
    "\ttrain_accuracies[neighbor] = knn.score(X_train, y_train)\n",
    "\ttest_accuracies[neighbor] = knn.score(X_test, y_test)\n",
    "print(neighbors, '\\n', train_accuracies, '\\n', test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add a title\n",
    "plt.title(\"KNN: Varying Number of Neighbors\")\n",
    "\n",
    "# Plot training accuracies\n",
    "plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n",
    "\n",
    "# Plot test accuracies\n",
    "plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intro To Regression \n",
    "<b>from sklearn.linear_model import LinearRegression</b> Used below \\\n",
    "<b>reg = LinearRegression()</b> Instantiate the model \\\n",
    "<b>reg.fit(X, y)</b> Fit the model \\\n",
    "<b>predictions = reg.predict(X)</b> Gives line of best fit \\\n",
    "<b>plt.scatter(X, y)</b> Plot values \\\n",
    "<b>plt.plot(x, predictions)</b> Plot line of best fit \\\n",
    "<b>reg_var.score(X_test, y_test)</b> R-squared score to check variance. Values range from 0 to 1 with 1 meaning features completely explain the target's variance \\\n",
    "<b>from sklearn.metrics import mean_squared_error</b> Used to get MSE \\\n",
    "<b>mean_squared_error(y_test, y_pred, squared=False)</b> Gives RMSE which is the square root of MSE(squared=False) \\\n",
    "Cross-validation: \\\n",
    "<b>from sklearn.model_selection import cross_val_score, KFold</b> Used below \\\n",
    "<b>kf = KFold(n_splits=6, shuffle=True, random_state=42)</b> Shuffle data before we split the data into folds \\\n",
    "<b>cv_result = cross_val_score(reg, X, y, cv=kf)</b> Arguments: model, feature data, target data, and number of folds. R-squared is returned \\\n",
    "Regularized regression: \\\n",
    "Large coefficients on line of best fit can lead to overfitting, so regularization penalizes large coefficients \\\n",
    "<b>from sklearn.linear_model import Ridge</b> Used below \\\n",
    "loop through alpha values when fitting the model \\\n",
    "<b>ridge = Ridge(alpha=alpha)</b> alpha can be a list of values \\ \n",
    "<b>from sklearn.linear_model import Lasso</b> Another type of regularized regression. Can be used to assess feature importance \\\n",
    "<b>lasso = Lasso(alpha=0.1)</b> Used below \\\n",
    "<b>lasso_coef = lasso.fit(X, y).coef_</b> Can plot this to see what feature affects target variable the most \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sales_df = pd.read_csv(\"advertising_and_sales_clean.csv\")\n",
    "\n",
    "# Create X from the radio column's values\n",
    "X = sales_df[\"radio\"].values\n",
    "\n",
    "# Create y from the sales column's values\n",
    "y = sales_df[\"sales\"].values\n",
    "\n",
    "# Reshape X\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "# Check the shape of the features and targets\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = reg.predict(X)\n",
    "\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(X, y, color=\"blue\")\n",
    "\n",
    "# Create line plot\n",
    "plt.plot(X, predictions, color=\"red\")\n",
    "plt.xlabel(\"Radio Expenditure ($)\")\n",
    "plt.ylabel(\"Sales ($)\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X, an array containing values of all features in sales_df, and y, containing all values from the \"sales\" column.\n",
    "X = sales_df.drop(\"sales\", axis=1).values\n",
    "y = sales_df[\"sales\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute R-squared\n",
    "r_squared = reg.score(X_test, y_test)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"R^2: {}\".format(r_squared))\n",
    "print(\"RMSE: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=5)\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Compute 6-fold cross-validation scores\n",
    "cv_scores = cross_val_score(reg, X, y, cv=kf)\n",
    "\n",
    "# Print scores\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean\n",
    "print(np.mean(cv_results))\n",
    "\n",
    "# Print the standard deviation\n",
    "print(np.std(cv_results))\n",
    "\n",
    "# Print the 95% confidence interval\n",
    "print(np.quantile(cv_results, [0.025, 0.975]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "ridge_scores = []\n",
    "for alpha in alphas:\n",
    "  \n",
    "  # Create a Ridge regression model\n",
    "  ridge = Ridge(alpha=alpha)\n",
    "  \n",
    "  # Fit the data\n",
    "  ridge.fit(X_train, y_train)\n",
    "  \n",
    "  # Obtain R-squared\n",
    "  score = ridge.score(X_test, y_test)\n",
    "  ridge_scores.append(score)\n",
    "print(ridge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Instantiate a lasso regression model\n",
    "lasso = Lasso(alpha=0.3)\n",
    "\n",
    "# Fit the model to the data\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Compute and print the coefficients\n",
    "lasso_coef = lasso.coef_\n",
    "print(lasso_coef)\n",
    "plt.bar(sales_columns, lasso_coef)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-Tuning Your Model\n",
    "<b>from sklearn.metrics import classification_report, confusion_matrix</b> Used below \\\n",
    "<b>confusion_matrix(y_test, y_pred)</b> Returns confusion matrix \\\n",
    "<b>classification_report(x_test, y_pred)</b> Returns metrics like precision, recall(sensitivity), and f1-score \\\n",
    "<b>Recall</b> If model needs to reduce false negatives this metric is most useful \\\n",
    "<b>from sklearn.linear_model import LogisticRegression</b> Logistic regression is used for classification. This model calculates the probability, p, that an observation belongs to a binary class. The default probability threshold for logistic regression in scikit-learn is zero-point-five \\\n",
    "<b>The ROC curve</b> Used to visualize how different thresholds affect true positive and false positive rates. If The ROC curve is above the dotted line the model performs better than randomly guessing the class of each observation. \\\n",
    "<b>from sklearn.metrics import roc_curve</b> For ROC curve \\\n",
    "<b>y_pred_probs = logreg.predict_proba(X_test)[:, 1]</b> Used below \\\n",
    "<b>fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)</b> unpack the results into three variables: false positive rate, FPR; true positive rate, TPR; and the thresholds. \\\n",
    "<b>from sklearn.metrics import roc_auc_score </b> To calculate area under curve \\\n",
    "<b>roc_auc_score(y_test, y_pred_probs)</b> Calculate area under curve \\\n",
    "Hyperparameters: Parameters we specify before fitting the model like alpha and n_neighbors \\\n",
    "For hyperparameter tuning it is essential to use cross validation to avoid overfitting \\\n",
    "GridSearchCV: \\\n",
    "param_grid = {\"alpha\": np.arrange(0.0001, 1, 10), \"solver\": [\"sag\", \"lsqr\"]} Used below \\\n",
    "<b>ridge_cv = GridSearchCV(ridge, param_grid, cv=kf)</b> model named ridge \\\n",
    "<b>ridge_cv.best_params_, ridge_cv.best_score_</b> Print metrics \\\n",
    "<b>from sklearn.model_selection import RandomizedSearchCV</b> RandomizedSearchCV, which tests a fixed number of hyperparameter settings from specified probability distributions. Used below \\\n",
    "<b>ridge_cv = GridSearchCV(ridge, param_grid, cv=kf, n_iter=2)</b> Scales better than GridSearchCV \\\n",
    "<b>ridge_cv.score(X_test, y_test)</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(y_pred_probs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Plot tpr against fpr\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Diabetes Prediction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred_probs))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\"alpha\": np.linspace(0.00001, 1, 20)}\n",
    "\n",
    "# Instantiate lasso_cv\n",
    "lasso_cv = GridSearchCV(lasso, param_grid, cv=kf)\n",
    "\n",
    "# Fit to the training data\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "print(\"Tuned lasso paramaters: {}\".format(lasso_cv.best_params_))\n",
    "print(\"Tuned lasso score: {}\".format(lasso_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter space\n",
    "params = {\"penalty\": [\"l1\", \"l2\"],\n",
    "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
    "         \"C\": np.linspace(0.1, 1.0, 50),\n",
    "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "logreg_cv = RandomizedSearchCV(logreg, params, cv=kf)\n",
    "\n",
    "# Fit the data to the model\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing and Pipelines\n",
    "Dummy variables or OneHotEncoder: \\\n",
    "<b>df_dummies = pd.get_dummies(df[\"col1\"], drop_first=True)</b> Need drop_first for some ML algorithms. If a observation is not part of the columns categories then it is the category we droped in drop_first. Have 10 categories we drop first cat. If observation is not part of the 9 cats then it is the cat we dropped  \\\n",
    "<b>df_dummies = pd.concat([df, df_dummies], axis=1)</b> Undo OneHotEncodeing \\\n",
    "<b>df = pd.get_dummies(df, drop_first=True)</b> If DF only has one cat feature you can pass the whole DF \\\n",
    "Handle missing data: \\\n",
    "<b>df.isna().sum.sort_values()</b>Get sum of na values in df \\\n",
    "Common practice is to drop na if 5% or less of all data is na \\\n",
    "<b>df.dropna(subset=[\"col_3%\", \"col_4%\", \"col_1%\"])</b> Drop cols with 5% of less of na values \\\n",
    "Input missing data(Make guess on missing data) \\\n",
    "<b>from sklearn.impute import SimpleImputer</b> Used below \\\n",
    "<b>imp_cat = SimpleImputer(strategy=\"most_frequent\")</b> Handle missing data by most frequent \\\n",
    "<b>imp_cat.fit_transform(X_train)</b> Fit and transform the data \\\n",
    "<b>from sklearn.pipeline import Pipeline</b> Used below \\\n",
    "<b>steps = [(\"imputation\", SimpleImputer()), (\"logistic_regression\", LogisticRegression())]</b> Used below \\\n",
    "<b>pipeline = Pipeline(steps)</b> Create pipeline \\ \n",
    "<b>pipeline.fit(), pipeline.score()</b> Get accuracy \\\n",
    "\n",
    "There are several ways to scale our data: given any column, we can subtract the mean and divide by the variance so that all features are centered around zero and have a variance of one. This is called standardization. We can also subtract the minimum and divide by the range of the data so the normalized dataset has minimum zero and maximum one. Or, we can center our data so that it ranges from -1 to 1 instead. \\\n",
    "<b>from sklearn.preprocessing import StandardScaler</b> Used below \\\n",
    "<b>X_train_scaled = scaler.fit_transform(X_train)</b> \\ \n",
    "<b>X_test_scaled = scaler.transform(X_test)</b> \\\n",
    "<b>cv = GridSearchCV(pipeline, param_grid=parameters)</b> CV and scaling in a pipeline \\\n",
    "Models metrics: \\\n",
    "Regression model performance: RMSE, R-squared \\\n",
    "Classification: Accuracy, confusion matrix, Precision, recall, F1-score, ROC AUC \\\n",
    "<b>from sklearn.tree import DecisionTreeClassifie</b> Used below \\\n",
    "Workflow:\n",
    "As usual, we create our feature and target arrays, then split our data. We then scale our features using the scaler's dot-fit_transform method on the training set, and the dot-transform method on the test set. \\\n",
    "\n",
    "Evaluating classification models \\\n",
    "We create a dictionary with our model names as strings for the keys, and instantiate models as the dictionary's values. We also create an empty list to store the results. Now we loop through the models in our models dictionary, using its dot-values method. Inside the loop, we instantiate a KFold object. Next we perform cross-validation, using the model being iterated, along with our scaled training features, and target training array. We set cv equal to our kfold variable. By default, the scoring here will be accuracy. We then append the cross-validation results to our results list. Lastly, outside of the loop, we create a boxplot of our results, and set the labels argument equal to a call of models-dot-keys to retrieve each model's name. \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, drop_first=True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be evaluated by calculating the average RMSE, but first, you will need to convert the scores for each fold to positive values and take their square root. This metric shows the average error of our model's predictions, so it can be compared against the standard deviation of the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print missing values for each column\n",
    "print(music_df.isna().sum().sort_values())\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=[\"genre\", \"popularity\", \"loudness\", \"liveness\", \"tempo\"])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"imputer\", imp_mean),\n",
    "        (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Linear Regression\": LinearRegression(), \"Ridge\": Ridge(alpha=0.1), \"Lasso\": Lasso(alpha=0.1)}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "  \n",
    "  # Append the results\n",
    "  results.append(cv_scores)\n",
    "\n",
    "# Create a box plot of the results\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for name, model in models.items():\n",
    "  \n",
    "  # Fit the model to the training data\n",
    "  model.fit(X_train_scaled, y_train)\n",
    "  \n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test_scaled)\n",
    "  \n",
    "  # Calculate the test_rmse\n",
    "  test_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "  print(\"{} Test Set RMSE: {}\".format(name, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree Classifier\": DecisionTreeClassifier()}\n",
    "results = []\n",
    "\n",
    "# Loop through the models' values\n",
    "for model in models.values():\n",
    "  \n",
    "  # Instantiate a KFold object\n",
    "  kf = KFold(n_splits=6, random_state=12, shuffle=True)\n",
    "  \n",
    "  # Perform cross-validation\n",
    "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
    "  results.append(cv_results)\n",
    "plt.boxplot(results, labels=models.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create steps\n",
    "steps = [(\"imp_mean\", SimpleImputer()), \n",
    "         (\"scaler\", StandardScaler()), \n",
    "         (\"logreg\", LogisticRegression())]\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "params = {\"logreg__solver\": [\"newton-cg\", \"saga\", \"lbfgs\"],\n",
    "         \"logreg__C\": np.linspace(0.001, 1.0, 10)}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "tuning = GridSearchCV(pipeline, param_grid=params)\n",
    "tuning.fit(X_train, y_train)\n",
    "y_pred = tuning.predict(X_test)\n",
    "\n",
    "# Compute and print performance\n",
    "print(\"Tuned Logistic Regression Parameters: {}, Accuracy: {}\".format(tuning.best_params_, tuning.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f51fba3d43c57b17b163e71fbbb3db01d8855d2be5857b3f133c22d8c8ed697"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
