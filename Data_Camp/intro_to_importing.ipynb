{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Importing Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>file = open(filename_var, mode=\"r\")</b> r means to open in read mode. \\\n",
    "<b>text_var = filename_var.read()</b> Reads text in file and saves it to text_var variable. Make sure to close the file when done with file.close() \\\n",
    "<b>with open(\"file_name.txt\", 'r') as file:</b> Now you do not have to close the file. \\\n",
    "<b>vaar = np.loadtext(filename, delimiter=',', skiprow=1, usecols=[0, 2], dtype=str)</b>Default delimiter is any whitespace, use skiprow when for example you only have ints in dataset but first row is a header and we want to ignore it. usecols only loads text from columns 0-2. dtype=str will assure all data entries are imported as strings \\\n",
    "<b>data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)</b>Used if there are diff dtypes for diff columns. np.genfromtxt() with dtype=None argument handles this. Names tells us there is a header \\\n",
    "<b>d = np.recfromcsv(file)</b> Same as np.genfromtxt except delimiter=',', names=True and dtype=None are default. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file: file\n",
    "file = open(\"moby_dick.txt\", \"r\")\n",
    " \n",
    "# Print it\n",
    "print(file.read())\n",
    " \n",
    "# Check whether file is closed\n",
    "print(file.closed)\n",
    " \n",
    "# Close file\n",
    "file.close()\n",
    " \n",
    "# Check whether file is closed\n",
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read & print the first 3 lines\n",
    "with open('moby_dick.txt') as file:\n",
    "   print(file.readline())\n",
    "   print(file.readline())\n",
    "   print(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    " \n",
    "# Assign the filename: file\n",
    "file = 'digits_header.txt'\n",
    " \n",
    "# Load the data: data\n",
    "data = np.loadtxt(file, delimiter='\\t', skiprows=1, usecols=[0,3])\n",
    " \n",
    "# Print data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign filename: file\n",
    "file = 'seaslug.txt'\n",
    " \n",
    "# Import file: data\n",
    "data = np.loadtxt(file, delimiter='\\t', dtype=str)\n",
    " \n",
    "# Print the first element of data\n",
    "print(data[0])\n",
    " \n",
    "# Import data as floats and skip the first row: data_float\n",
    "data_float = np.loadtxt(file, delimiter=\"\\t\", dtype=float, skiprows=1)\n",
    " \n",
    "# Print the 10th element of data_float\n",
    "print(data_float[9])\n",
    " \n",
    "# Plot a scatterplot of the data\n",
    "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('percentage of larvae')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Assign filename: file\n",
    "file = 'titanic_corrupt.txt'\n",
    " \n",
    "# Import file: data\n",
    "# sep (the pandas version of delim),\n",
    "data = pd.read_csv(file, sep=\"\\t\", comment=\"#\", na_values=\"Nothing\")\n",
    " \n",
    "# Print the head of the DataFrame\n",
    "print(data.head())\n",
    " \n",
    "# Plot 'Age' variable in a histogram\n",
    "pd.DataFrame.hist(data[['Age']])\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to other file types\n",
    "<b>with open(\"filename.pkl\", \"rb\") as file</b> rb is read binary since pickle files are converted to binary. Use pickle.load(file) to read data. \\\n",
    "<b>data_var = pd.ExcelFile(file)</b> To import excel sheet \\\n",
    "<b>print(data_var.sheet_names)</b> To see names of sheet in excel file \\\n",
    "<b>df1 = data.parse(\"sheet_name1\")</b> Loads sheet named sheet_name1 as a dataframe. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickle package\n",
    "import pickle\n",
    " \n",
    "# Open pickle file and load data: d\n",
    "with open('data.pkl', \"rb\") as file:\n",
    "   d = pickle.load(file)\n",
    " \n",
    "# Print d\n",
    "print(d)\n",
    " \n",
    "# Print datatype of d\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    " \n",
    "# Assign spreadsheet filename: file\n",
    "file = \"battledeath.xlsx\"\n",
    " \n",
    "# Load spreadsheet: xls\n",
    "xls = pd.ExcelFile(file)\n",
    " \n",
    "# Print sheet names\n",
    "print(xls.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sheet into a DataFrame by name: df1\n",
    "df1 = xls.parse(\"2004\")\n",
    " \n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    " \n",
    "# Load the sheet 2002 into the DataFrame df2 using its index (0).\n",
    "df2 = xls.parse(0)\n",
    " \n",
    "# Print the head of the DataFrame df2\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the first sheet and rename the columns: df1\n",
    "df1 = xls.parse(0, skiprows=[0], names=[\"Country\", \"AAM due to War (2002)\"])\n",
    " \n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    " \n",
    "# Parse the first column of the second sheet and rename the column: df2\n",
    "df2 = xls.parse(1, usecols=[0], skiprows=1, names=[\"Country\"])\n",
    " \n",
    "# Print the head of the DataFrame df2\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Relational Databases in Python\n",
    "<b>Querying:</b> getting data out from the database \\\n",
    "<b>from sqlalchemy import create_engine</b> Need this method to connected to a relational database \\\n",
    "<b>var = create_engine(\"sqlite:///DB_name.sqlite\")</b> Create SQL engine that will communicate our queries to the database \\\n",
    "<b>con = engine.connect()</b> connect to the engine \\ \n",
    "<b>table_names = engine.table_names()</b> Use print() to show all tables in the DB \\\n",
    "<b>SELECT * FROM Table_Name</b> Returns all columns of all rows of the table \"Table_Name\" \\\n",
    "<b>var = con.execute(\"SELECT * FROM Table_Name\")</b> Python code to execute above sequel code \\\n",
    "<b>df = pd.DataFrame(var.fetchall())</b> Convert results object var and save to pandas DataFrame \\\n",
    "<b>df = pd.DataFrame(var.fetchmany(size=5))</b> Fetches five rows instead of all rows\n",
    "<b>con.close()</b> Close the connection \\\n",
    "<b>df.columns = rs.keys()</b> Use if column names are displayed wrong \\\n",
    "<b>with engine.connect() as con:</b> Dont have to close connection now, good practice \\\n",
    "<b>df = pd.read_sql_query(\"SELECT * FROM Table_Names\", engine)</b> First argument is the query you want to make and second is the engine you want to connect to \\\n",
    "<b>(\"SELECT col1_table1, col3_table2 FROM table1 INNER JOIN table2 on table1.col2 = table2.col1\")</b> Do inner join on columns table1.col2 and table2.col1 and output col1_table1 from table 1 and col3_table2 from table 2.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary module\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Save the table names to a list: table_names\n",
    "table_names = engine.table_names()\n",
    "\n",
    "# Print the table names to the shell\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Open engine connection: con\n",
    "con = engine.connect()\n",
    "\n",
    "# Perform query that selects ALL columns from the Album table : rs\n",
    "rs = con.execute(\"SELECT * FROM Album\")\n",
    "\n",
    "# Save results of the query to DataFrame: df\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "# Close connection\n",
    "con.close()\n",
    "\n",
    "# Print head of DataFrame df\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT LastName, Title FROM Employee\")\n",
    "    df = pd.DataFrame(rs.fetchmany(size=3))\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print the length of the DataFrame df\n",
    "print(len(df))\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT * FROM Employee WHERE EmployeeID >= 6\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    # Set the DataFrame's column names to the \n",
    "    # corresponding names of the table columns.\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Open engine in context manager\n",
    "with engine.connect() as con:\n",
    "    # Selects all records from the Employee table and\n",
    "    # orders them in increasing order by the column BirthDate\n",
    "    rs = con.execute(\"SELECT * FROM Employee ORDER BY BirthDate\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "    # Set the DataFrame's column names\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine(\"sqlite:///Chinook.sqlite\")\n",
    "\n",
    "# Execute query and store records in DataFrame: df\n",
    "df = pd.read_sql_query(\"SELECT * FROM Employee WHERE EmployeeId >= 6 ORDER BY BirthDate\", engine)\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT Title, Name FROM Album INNER JOIN Artist on Album.ArtistID = Artist.ArtistID\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print head of DataFrame df\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute query and store records in DataFrame: df\n",
    "df = pd.read_sql_query(\"SELECT * FROM PlaylistTrack INNER JOIN Track on PlaylistTrack.TrackId = Track.TrackId WHERE Milliseconds < 250000\", engine)\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Data from the Internet\n",
    "<b>from urllib.request import urlretrieve</b> \n",
    "<b>urlretrieve(url_var, \"filename.csv\")</b> Get data from url_var and save it into a file name filename.csv \\\n",
    "<b>import requests</b>\n",
    "<b>r = requests.get(url_var)</b> Send a get request to given url and catch the response \\\n",
    "<b>text = r.text</b> Returns HTML as a string \\ \n",
    "<b>soup = BeautifulSoup(html_doc)</b> Create beautiful soup object from the resulting HTML \\\n",
    "<b>print(soup.prettify())</b> Make the HTML look \"pretty\" \\\n",
    "<b>soup.title, soup.get_text(), for link in soup.find_all('a'):</b> Different methods avaliable \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, \"winequality-red.csv\")\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Read file into a DataFrame: df\n",
    "df = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Plot first column of df\n",
    "df.iloc[:, 0].hist()\n",
    "plt.xlabel('fixed acidity (g(tartaric acid)/dm$^3$)')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually send and catch the get request and response \n",
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
    "\n",
    "# This packages the request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Extract the response: html\n",
    "html = response.read()\n",
    "\n",
    "# Print the html\n",
    "print(html)\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use method to do above code\n",
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Specify the url: url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "# Packages the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response: text\n",
    "text = r.text\n",
    "\n",
    "# Print the html\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Prettify the BeautifulSoup object: pretty_soup\n",
    "pretty_soup = soup.prettify()\n",
    "\n",
    "# Print the response\n",
    "print(pretty_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.title)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all(\"a\")\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interacting with APIs to import data from the web\n",
    "<b>with open(\"name.json\", \"r\") as json_file:</b> Open json file located in local directory \\\n",
    "<b>var = json.load(json_file)</b> Load json file. Will be Imported as a dict \\\n",
    "<b>for key, value in var.items():</b> Iterate over the key/value pairs inside the dict \\ \n",
    "<b>json_data = r.json()</b> r is defined using request.get(url) method. Returns dict \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON: json_data\n",
    "with open(\"a_movie.json\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'http://www.omdbapi.com/?apikey=72bc447a&t=social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f51fba3d43c57b17b163e71fbbb3db01d8855d2be5857b3f133c22d8c8ed697"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
